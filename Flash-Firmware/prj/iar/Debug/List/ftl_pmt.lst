###############################################################################
#
# IAR ANSI C/C++ Compiler V7.40.5.9725/W32 for ARM        28/Oct/2023  18:58:36
# Copyright 1999-2015 IAR Systems AB.
#
#    Cpu mode     =  thumb
#    Endian       =  little
#    Source file  =  
#        C:\Users\bchen-adm\Desktop\nsac-hiftl-dc\core\ftl\ftl_pmt.c
#    Command line =  
#        C:\Users\bchen-adm\Desktop\nsac-hiftl-dc\core\ftl\ftl_pmt.c -D
#        BOOT_LEVEL_2 -lcN
#        C:\Users\bchen-adm\Desktop\nsac-hiftl-dc\prj\iar\Debug\List -o
#        C:\Users\bchen-adm\Desktop\nsac-hiftl-dc\prj\iar\Debug\Obj --no_cse
#        --no_unroll --no_inline --no_code_motion --no_tbaa --no_clustering
#        --no_scheduling --debug --endian=little --cpu=ARM926EJ-S -e --fpu=None
#        --dlib_config "C:\Program Files (x86)\IAR Systems\Embedded Workbench
#        7.2\arm\INC\c\DLib_Config_Normal.h" -I
#        C:\Users\bchen-adm\Desktop\nsac-hiftl-dc\prj\iar\..\..\ -I
#        C:\Users\bchen-adm\Desktop\nsac-hiftl-dc\prj\iar\..\..\sys\lpc313x\bsp\
#        -I
#        C:\Users\bchen-adm\Desktop\nsac-hiftl-dc\prj\iar\..\..\sys\lpc313x\csp\
#        -I
#        C:\Users\bchen-adm\Desktop\nsac-hiftl-dc\prj\iar\..\..\sys\lpc313x\lib\
#        -I
#        C:\Users\bchen-adm\Desktop\nsac-hiftl-dc\prj\iar\..\..\sys\lpc313x\usb\
#        --cpu_mode thumb -Ol --use_c++_inline
#    List file    =  
#        C:\Users\bchen-adm\Desktop\nsac-hiftl-dc\prj\iar\Debug\List\ftl_pmt.lst
#    Object file  =  
#        C:\Users\bchen-adm\Desktop\nsac-hiftl-dc\prj\iar\Debug\Obj\ftl_pmt.o
#
###############################################################################

C:\Users\bchen-adm\Desktop\nsac-hiftl-dc\core\ftl\ftl_pmt.c
      1          /*********************************************************
      2           * Module name: ftl_pmt.c
      3           *
      4           * Copyright 2010, 2011. All Rights Reserved, Crane Chu.
      5           *
      6           * This file is part of OpenNFM.
      7           *
      8           * OpenNFM is free software: you can redistribute it and/or 
      9           * modify it under the terms of the GNU General Public 
     10           * License as published by the Free Software Foundation, 
     11           * either version 3 of the License, or (at your option) any 
     12           * later version.
     13           * 
     14           * OpenNFM is distributed in the hope that it will be useful,
     15           * but WITHOUT ANY WARRANTY; without even the implied 
     16           * warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR 
     17           * PURPOSE. See the GNU General Public License for more 
     18           * details.
     19           *
     20           * You should have received a copy of the GNU General Public 
     21           * License along with OpenNFM. If not, see 
     22           * <http://www.gnu.org/licenses/>.
     23           *
     24           * First written on 2010-01-01 by cranechu@gmail.com
     25           * Updated by vinay.g.jain@gmail.com on Nov 22 2014.
     26           *
     27           * Module Description:
     28           *    Page Mapping Table. It contains 2 layers of table. 
     29           *    The first layer is ROOT, and points to every second
     30           *       layer of PMT (aka. CLUSTER)
     31           *    The second layer is PMT pages, and holding logical 
     32           *       page mapping info, pointing to UBI block/page.
     33           *
     34           *********************************************************/
     35          
     36          #include <core\inc\cmn.h>
     37          #include <core\inc\ftl.h>
     38          #include <core\inc\ubi.h>
     39          #include <sys\sys.h>
     40          #include "ftl_inc.h"
     41          
     42          #define PMT_CURRENT_BLOCK  (PM_NODE_BLOCK(root_table.pmt_current_block))
     43          #define PMT_CURRENT_PAGE   (PM_NODE_PAGE(root_table.pmt_current_block))
     44          #define PMT_RECLAIM_BLOCK  (PM_NODE_BLOCK(root_table.pmt_reclaim_block))
     45          #define PMT_RECLAIM_PAGE   (PM_NODE_PAGE(root_table.pmt_reclaim_block))
     46          
     47          #if defined(__ICCARM__)
     48          /* must be aligned to 4bytes, because the lowest 2 bits is reserved */
     49          #pragma data_alignment=4
     50          #endif
     51          static PM_NODE pm_node_caches[PMT_CACHE_COUNT];
     52          static PM_NODE_ADDR pm_cache_origin_location[PMT_CACHE_COUNT];
     53          static PMT_CLUSTER pm_cache_cluster[PMT_CACHE_COUNT];
     54          /* meta data in last page */
     55          static PMT_CLUSTER meta_data[PAGE_PER_PHY_BLOCK];
     56          /* buffer used in reclaim */
     57          static PMT_CLUSTER clusters[MPP_SIZE / sizeof(PMT_CLUSTER)];
     58          static UINT8 pm_node_buffer[MPP_SIZE];
     59          
     60          static STATUS pmt_reclaim_blocks();
     61          
     62          STATUS PMT_Format() {
     63            LOG_BLOCK pmt_block = PMT_START_BLOCK;
     64            PAGE_OFF pmt_page = 0;
     65            PM_NODE pm_node;
     66            STATUS ret = STATUS_SUCCESS;
     67            SPARE spare;
     68            UINT32 i;
     69            UINT32 j;
     70            UINT32 pmt_cluster_count = ((FTL_Capacity() + PM_PER_NODE - 1) /  PM_PER_NODE);//471
     71          
     72            /* root table has enough space to hold 1st level of pmt */
     73            ASSERT(pmt_cluster_count < MAX_PM_CLUSTERS);
     74          
     75            for (i = 0; i < pmt_cluster_count; i++) {
     76              if (ret == STATUS_SUCCESS) {
     77                /* format a cluster of PMT */
     78                for (j = 0; j < PM_PER_NODE; j++) {//512
     79                  pm_node[j] = INVALID_PM_NODE;
     80                }
     81                spare[0] = i;
     82                ret = UBI_Write(pmt_block, pmt_page, pm_node, spare, FALSE);
     83              }
     84          
     85              if (ret == STATUS_SUCCESS) {
     86                meta_data[pmt_page] = i;
     87          
     88                PM_NODE_SET_BLOCKPAGE(root_table.page_mapping_nodes[i], pmt_block, pmt_page);
     89          
     90                /* last page is reserved for meta data */
     91                if (pmt_page < PAGE_PER_PHY_BLOCK - 1) {
     92                  pmt_page++;
     93                }
     94          
     95                if (pmt_page == PAGE_PER_PHY_BLOCK - 1) {
     96                  ret = UBI_Write(pmt_block, pmt_page, meta_data, NULL, FALSE);
     97                  if (ret == STATUS_SUCCESS) {
     98                    block_dirty_table[pmt_block] = 0;
     99                    pmt_page = 0;
    100                    pmt_block++;
    101                  }
    102                }
    103              }
    104            }
    105          
    106            if (ret == STATUS_SUCCESS) {
    107              /* set journal blocks */
    108              PM_NODE_SET_BLOCKPAGE(root_table.pmt_current_block, pmt_block, pmt_page);
    109              PM_NODE_SET_BLOCKPAGE(root_table.pmt_reclaim_block, pmt_block + 1, 0);
    110          
    111              /* update block dirty table */
    112              block_dirty_table[pmt_block] = 0;
    113              block_dirty_table[pmt_block + 1] = 0;//为什么设置这个块??
    114            }
    115          
    116            return ret;
    117          }
    118          
    119          STATUS PMT_Init() {
    120            UINT32 i;
    121            STATUS ret = STATUS_SUCCESS;
    122          
    123            /* init cache */
    124            for (i = 0; i < PMT_CACHE_COUNT; i++) {//4
    125              memset(pm_node_caches[i], 0, MPP_SIZE);
    126              pm_cache_origin_location[i] = INVALID_PM_NODE;
    127              pm_cache_cluster[i] = INVALID_CLUSTER;
    128            }
    129          
    130            /* PLR: the PMT is only validated after writing ROOT. do some test. */
    131            return ret;
    132          }
    133          
    134          STATUS PMT_Update(PGADDR page_addr, LOG_BLOCK block, PAGE_OFF page) {
    135            PMT_CLUSTER cluster = CLUSTER_INDEX(page_addr);//计算逻辑I地址所在簇号
    136            PM_NODE_ADDR* cluster_addr;
    137            LOG_BLOCK edit_block;
    138            STATUS ret = STATUS_SUCCESS;
    139          
    140            if (PM_NODE_IS_CACHED(root_table.page_mapping_nodes[cluster]) == FALSE) {
    141              /* load page in cache before updating bdt/hdi/root,
    142               * because it may cause a commit. */
    143              ret = PMT_Load(PM_NODE_BLOCK(root_table.page_mapping_nodes[cluster]),
    144                             PM_NODE_PAGE(root_table.page_mapping_nodes[cluster]),
    145                             cluster);
    146            }
    147          
    148            if (ret == STATUS_SUCCESS) {
    149              cluster_addr = PM_NODE_ADDRESS(root_table.page_mapping_nodes[cluster]);
    150              if (cluster_addr[PAGE_IN_CLUSTER(page_addr)] != INVALID_PM_NODE) {
    151                /* update BDT: increase dirty page count of the edited data block */
    152                edit_block = PM_NODE_BLOCK(cluster_addr[PAGE_IN_CLUSTER(page_addr)]);
    153                block_dirty_table[edit_block]++;
    154                ASSERT(block_dirty_table[edit_block] <= MAX_DIRTY_PAGES);
    155              }
    156          
    157              /* update PMT */
    158              if (block != INVALID_BLOCK) {
    159                ASSERT(page != INVALID_PAGE);
    160                PM_NODE_SET_BLOCKPAGE(cluster_addr[PAGE_IN_CLUSTER(page_addr)], block, page);
    161              } else {
    162                /* trim page, set it invalid page in PMT, and it will be
    163                 * discarded in the next reclaim.
    164                 */
    165                ASSERT(page == INVALID_PAGE);
    166                cluster_addr[PAGE_IN_CLUSTER(page_addr)] = INVALID_PM_NODE;
    167              }
    168          
    169              /* set dirty bit */
    170              PM_NODE_SET_DIRTY(root_table.page_mapping_nodes[cluster]);
    171            }
    172          
    173            return ret;
    174          }
    175          
    176          STATUS PMT_Search(PGADDR page_addr, LOG_BLOCK* block, PAGE_OFF* page) {
    177            PMT_CLUSTER cluster = CLUSTER_INDEX(page_addr);
    178            PM_NODE_ADDR* cluster_addr;
    179            PM_NODE_ADDR pm_node;
    180            STATUS ret = STATUS_SUCCESS;
    181          
    182            if (PM_NODE_IS_CACHED(root_table.page_mapping_nodes[cluster]) == FALSE) {
    183              /* load page in cache */
    184              ret = PMT_Load(PM_NODE_BLOCK(root_table.page_mapping_nodes[cluster]),
    185                             PM_NODE_PAGE(root_table.page_mapping_nodes[cluster]),
    186                             cluster);
    187            }
    188          
    189            if (ret == STATUS_SUCCESS) {
    190              ASSERT(root_table.page_mapping_nodes[cluster] != INVALID_PM_NODE);
    191          
    192              cluster_addr = PM_NODE_ADDRESS(root_table.page_mapping_nodes[cluster]);
    193              ASSERT(cluster_addr != 0);
    194          
    195              pm_node = cluster_addr[PAGE_IN_CLUSTER(page_addr)];
    196              if (pm_node != INVALID_PM_NODE) {
    197                *block = PM_NODE_BLOCK(pm_node);
    198                *page = PM_NODE_PAGE(pm_node);
    199              } else {
    200                *block = INVALID_BLOCK;
    201                *page = INVALID_PAGE;
    202              }
    203            }
    204          
    205            return ret;
    206          }
    207          
    208          static STATUS PMT_Load(LOG_BLOCK block, PAGE_OFF page, PMT_CLUSTER cluster) {
    209            UINT32 i;
    210            PM_NODE_ADDR* cache_addr = NULL;
    211            STATUS ret = STATUS_SUCCESS;
    212          
    213            /* find the first empty cache slot */
    214            for (i = 0; i < PMT_CACHE_COUNT; i++) {
    215              if (pm_cache_origin_location[i] == INVALID_PM_NODE) {
    216                break;
    217              }
    218            }
    219          
    220            if (i == PMT_CACHE_COUNT) {
    221              i = 0;
    222          
    223              /* cache is full, commit to nand, and release all cache */
    224              ret = DATA_Commit();
    225              if (ret == STATUS_SUCCESS) {
    226                /* use updated PMT block and page */
    227                block = PM_NODE_BLOCK(root_table.page_mapping_nodes[cluster]);
    228                page = PM_NODE_PAGE(root_table.page_mapping_nodes[cluster]);
    229              }
    230            }
    231          
    232            /* read out the PM node from UBI */
    233            if (ret == STATUS_SUCCESS) {
    234              cache_addr = &((pm_node_caches[i])[0]);
    235              ret = UBI_Read(block, page, cache_addr, NULL);
    236            }
    237          
    238            /* update cache info */
    239            if (ret == STATUS_SUCCESS) {
    240              PM_NODE_SET_BLOCKPAGE(pm_cache_origin_location[i], block, page);
    241          
    242              /* update the cache address in memory to PMT table */
    243              root_table.page_mapping_nodes[cluster] = (UINT32) (cache_addr);
    244          
    245              /* the page mapping should be clean in ram */
    246              ASSERT((((UINT32 )(cache_addr)) & 0x3) == 0);
    247          
    248              pm_cache_cluster[i] = cluster;
    249            }
    250          
    251            return ret;
    252          }
    253          
    254          /* write back dirty node to UBI, and clear all cache */
    255          STATUS PMT_Commit() {
    256            UINT32 i;
    257            PM_NODE_ADDR pm_node;
    258            STATUS ret = STATUS_SUCCESS;
    259          
    260            /* find the dirty cache nodes */
    261            for (i = 0; i < PMT_CACHE_COUNT; i++) {
    262              if (pm_cache_cluster[i] == INVALID_CLUSTER) {
    263                continue;
    264              }
    265          
    266              pm_node = root_table.page_mapping_nodes[pm_cache_cluster[i]];
    267              ASSERT(PM_NODE_IS_CACHED(pm_node) == TRUE);
    268              if (PM_NODE_IS_DIRTY(pm_node) == FALSE) {
    269                /* update pmt in root table */
    270                root_table.page_mapping_nodes[pm_cache_cluster[i]] =
    271                    pm_cache_origin_location[i];
    272                continue;
    273              }
    274          
    275              /* check empty page space */
    276              if (PMT_CURRENT_PAGE != PAGE_PER_PHY_BLOCK) {
    277                /* last page is reserved */
    278                ASSERT(PMT_CURRENT_PAGE != (PAGE_PER_PHY_BLOCK - 1));
    279          
    280                if (ret == STATUS_SUCCESS) {
    281                  /* write page to UBI */
    282                  ret = UBI_Write(PMT_CURRENT_BLOCK, PMT_CURRENT_PAGE,
    283                                  pm_node_caches[i], &pm_cache_cluster[i], FALSE);
    284                  if (ret == STATUS_SUCCESS) {
    285                    meta_data[PMT_CURRENT_PAGE] = pm_cache_cluster[i];
    286                  }
    287                }
    288          
    289                if (ret == STATUS_SUCCESS) {
    290                  PMT_CLUSTER pm_cluster = pm_cache_cluster[i];
    291                  LOG_BLOCK old_pm_block;
    292          
    293                  /* update pmt in root table */
    294                  PM_NODE_SET_BLOCKPAGE(root_table.page_mapping_nodes[pm_cluster],
    295                                        PMT_CURRENT_BLOCK, PMT_CURRENT_PAGE);
    296          
    297                  /* update pmt journal */
    298                  PM_NODE_SET_BLOCKPAGE(root_table.pmt_current_block, PMT_CURRENT_BLOCK,
    299                                        PMT_CURRENT_PAGE+1);
    300          
    301                  /* update the block dirty table */
    302                  old_pm_block = PM_NODE_BLOCK(pm_cache_origin_location[i]);
    303          
    304                  block_dirty_table[old_pm_block]++;
    305                  ASSERT(block_dirty_table[old_pm_block] <= MAX_DIRTY_PAGES);
    306                }
    307              }
    308          
    309              if (PMT_CURRENT_PAGE == PAGE_PER_PHY_BLOCK - 1) {
    310                if (ret == STATUS_SUCCESS) {
    311                  ret = UBI_Write(PMT_CURRENT_BLOCK, PMT_CURRENT_PAGE,
    312                                  meta_data, NULL, FALSE);
    313                }
    314          
    315                if (ret == STATUS_SUCCESS) {
    316                  /* flush WIP data on all dice */
    317                  ret = UBI_Flush();
    318                }
    319          
    320                if (ret == STATUS_SUCCESS) {
    321                  ret = pmt_reclaim_blocks();
    322                }
    323              }
    324            }
    325          
    326            if (ret == STATUS_SUCCESS) {
    327              /* init the PMT to clear all cache */
    328              ret = PMT_Init();
    329            }
    330          
    331            return ret;
    332          }
    333          
    334          static STATUS pmt_reclaim_blocks() {
    335            UINT32 i = 0;
    336            UINT32 found_block = 0;
    337            UINT32 total_valid_page = 0;
    338            PAGE_OFF next_dirty_count = 0;
    339            PAGE_OFF target_dirty_count = MAX_DIRTY_PAGES;//63
    340            STATUS ret = STATUS_SUCCESS;
    341          
    342            /* find dirtiest block in different dice as new journal blocks */
    343            while (found_block != 1) {
    344              for (i = PMT_START_BLOCK; i < PMT_START_BLOCK + PMT_BLOCK_COUNT; i++) {
    345                if (block_dirty_table[i] == target_dirty_count) {//63
    346                  /* try to erase it */
    347                  ret = UBI_ReadStatus(i);
    348                } else {
    349                  /* set the next target dirty count */
    350                  if (block_dirty_table[i] < target_dirty_count
    351                      && block_dirty_table[i] > next_dirty_count) {
    352                    next_dirty_count = block_dirty_table[i];
    353                  }
    354                  continue;
    355                }
    356          
    357                if (ret == STATUS_SUCCESS) {
    358                  /* find a dirtiest block */
    359                  total_valid_page = (MAX_DIRTY_PAGES - block_dirty_table[i]);
    360                  found_block = 1;
    361                  break;
    362                }
    363              }
    364              target_dirty_count = next_dirty_count;
    365            }
    366          
    367            if (ret == STATUS_SUCCESS) {
    368              if (total_valid_page != 0) {
    369                /* copy valid pages to the reclaim block */
    370                LOG_BLOCK reclaim_block;
    371                LOG_BLOCK dirty_block;
    372                PAGE_OFF reclaim_page = 0;
    373                PAGE_OFF page;
    374          
    375                reclaim_block = PM_NODE_BLOCK(root_table.pmt_reclaim_block);
    376                dirty_block = i;
    377          
    378                ret = UBI_Read(dirty_block, PAGE_PER_PHY_BLOCK - 1, clusters, NULL);
    379                if (ret == STATUS_SUCCESS) {
    380                  for (page = 0; page < PAGE_PER_PHY_BLOCK - 1; page++) {
    381                    PMT_CLUSTER cluster = clusters[page];
    382                    PM_NODE_ADDR pm_node = root_table.page_mapping_nodes[cluster];
    383                    UINT32 cleared_cache_index = INVALID_INDEX;
    384          
    385                    /* if cached, just need to copy clean page */
    386                    if (PM_NODE_IS_CACHED(pm_node) == TRUE) {
    387                      if (PM_NODE_IS_DIRTY(pm_node) == TRUE) {
    388                        /* dirty page will be re-written by commit */
    389                        pm_node = INVALID_PM_NODE;
    390                      } else {
    391                        /* reclaim clean cached pages */
    392                        UINT32 i;
    393          
    394                        for (i = 0; i < PMT_CACHE_COUNT; i++) {
    395                          if (pm_cache_cluster[i] == cluster) {
    396                            break;
    397                          }
    398                        }
    399          
    400                        ASSERT(i != PMT_CACHE_COUNT);
    401                        pm_node = pm_cache_origin_location[i];
    402                        cleared_cache_index = i;
    403                      }
    404                    }
    405          
    406                    if (pm_node != INVALID_PM_NODE &&
    407                    PM_NODE_BLOCK(pm_node) == dirty_block &&
    408                    PM_NODE_PAGE(pm_node) == page) {
    409                      /* copy valid page to reclaim block */
    410                      ret = UBI_Read(dirty_block, page, pm_node_buffer, NULL);
    411                      if (ret == STATUS_SUCCESS) {
    412                        ret = UBI_Write(reclaim_block, reclaim_page, pm_node_buffer, NULL,
    413                        FALSE);
    414                      }
    415          
    416                      if (ret == STATUS_SUCCESS) {
    417                        /* update mapping */
    418                        PM_NODE_SET_BLOCKPAGE(root_table.page_mapping_nodes[cluster],
    419                                              reclaim_block, reclaim_page);
    420                        meta_data[reclaim_page] = cluster;
    421                        reclaim_page++;
    422          
    423                        /* clear it from cache */
    424                        if (cleared_cache_index != INVALID_INDEX) {
    425                          memset(pm_node_caches[cleared_cache_index], 0, MPP_SIZE);
    426                          pm_cache_origin_location[cleared_cache_index] =
    427                          INVALID_PM_NODE;
    428                          pm_cache_cluster[cleared_cache_index] = INVALID_CLUSTER;
    429                        }
    430                      }
    431                    }
    432                  }
    433                }
    434          
    435                /* erase dirty block, and then update journals */
    436                if (ret == STATUS_SUCCESS) {
    437                  ret = UBI_Erase(dirty_block, dirty_block);
    438                }
    439          
    440                if (ret == STATUS_SUCCESS) {
    441                  PM_NODE_SET_BLOCKPAGE(root_table.pmt_current_block, reclaim_block,
    442                                        reclaim_page);
    443                  PM_NODE_SET_BLOCKPAGE(root_table.pmt_reclaim_block, dirty_block, 0);
    444          
    445                  /* reset the BDT */
    446                  block_dirty_table[reclaim_block] = 0;
    447                  block_dirty_table[dirty_block] = 0;
    448                }
    449              } else {
    450                if (ret == STATUS_SUCCESS) {
    451                  /* the die is NOT busy */
    452                  ret = UBI_Erase(i, i);
    453                }
    454          
    455                if (ret == STATUS_SUCCESS) {
    456                  PM_NODE_SET_BLOCKPAGE(root_table.pmt_current_block, i, 0);
    457          
    458                  /* reset the BDT */
    459                  block_dirty_table[i] = 0;
    460                }
    461              }
    462            }
    463          
    464            return ret;
    465          }

   Maximum stack usage in bytes:

   .cstack Function
   ------- --------
      16   PMT_Commit
        16   -> PMT_Init
        16   -> UBI_Flush
        16   -> UBI_Write
        16   -> pmt_reclaim_blocks
    2088   PMT_Format
      2088   -> FTL_Capacity
      2088   -> UBI_Write
      16   PMT_Init
        16   -> __aeabi_memset
      24   PMT_Load
        24   -> DATA_Commit
        24   -> UBI_Read
      24   PMT_Search
        24   -> PMT_Load
        24 __aeabi_uidivmod
      32   PMT_Update
        32   -> PMT_Load
        32 __aeabi_uidivmod
      40   pmt_reclaim_blocks
        40   -> UBI_Erase
        40   -> UBI_Read
        40   -> UBI_ReadStatus
        40   -> UBI_Write
        40   -> __aeabi_memset


   Section sizes:

   Bytes  Function/Label
   -----  --------------
       4  ??DataTable3
       4  ??DataTable3_1
       4  ??DataTable3_2
       4  ??DataTable3_3
       4  ??DataTable4
       4  ??DataTable4_1
       4  ??DataTable4_2
       4  ??DataTable4_3
       4  ??DataTable4_4
       4  ??DataTable5
       4  ??DataTable6
       4  ??DataTable6_1
       4  ??DataTable6_2
       4  ??DataTable6_3
       4  ??DataTable6_4
     382  PMT_Commit
     238  PMT_Format
      68  PMT_Init
     170  PMT_Load
     168  PMT_Search
     254  PMT_Update
    2048  clusters
     256  meta_data
      16  pm_cache_cluster
      16  pm_cache_origin_location
    2048  pm_node_buffer
    8192  pm_node_caches
     534  pmt_reclaim_blocks

 
 12 576 bytes in section .bss
  1 874 bytes in section .text
 
  1 874 bytes of CODE memory
 12 576 bytes of DATA memory

Errors: none
Warnings: none
